# code to create the summarisation for the large documents (more than 20-3o pages) 
import sys
#sys.path.append('c:/Arun/Workspace/OpenAI/Embeddings/utilities/')
sys.path.append('c:/Arun/Workspace/OpenAI/Azure-OpenAI-Summarisation-Embeddings-QnA/utilities/')

import os
# get the open AI completion for summasiation
from utilities import summarisation
from utilities import utils
from utilities import redisembeddings

# set Openai environment variables
os.environ["OPENAI_ENGINES"] = "text-davinci-003"
os.environ["OPENAI_EMBEDDINGS_ENGINE_DOC"] = "text-embedding-ada-002"
os.environ["OPENAI_EMBEDDINGS_ENGINE_QUERY"] = "text-embedding-ada-002"
os.environ["OPENAI_API_BASE"] = "https://demo-aoai.openai.azure.com/"
os.environ["OPENAI_API_KEY"] = "1cf9f4644ef448ffb294e60e4760ad08"
os.environ["OPENAI_CHUNK_LIMIT"] = "18000"
os.environ["REDIS_ADDRESS"] = "openaiembed-redis.uksouth.azurecontainer.io"
os.environ["REDIS_PASSWORD"] = "redisPwd123"
os.environ["FORM_RECOGNIZER_ENDPOINT"] = "https://formrecogforopenai.cognitiveservices.azure.com/"
os.environ["FORM_RECOGNIZER_KEY"] = "594107e182ba45e1a5b965f25b0bf0a4"
os.environ['BLOB_ACCOUNT_NAME'] = "openaiembedstr"
os.environ['BLOB_ACCOUNT_KEY'] = "sI4EOYwzvWGOYP9O72vpvsyO9RVNHNXrXaHcFH+5c5IZKd+7eLFGNvouRNZ1a7Krd10w55lifhKk+AStphGxuQ=="
os.environ['BLOB_CONTAINER_NAME'] = "documents"
os.environ['BLOB_CONTAINER_NAME'] = "documents"
os.putenv('PAGES_PER_EMBEDDINGS',"1")



# full path of the document that needs embed and search
fullpath="https://openaiembedstr.blob.core.windows.net/documents/21252030 Agenda for Sustainable Development web.pdf"
filename="21252030 Agenda for Sustainable Development web.pdf"

# initialise all the required parameters for OpenAI to run
df = summarisation.initialize(engine='davinci')

# submit the docment to summarise before embeddings search
response = summarisation.convert_file_and_add_summarisation_and_embed(fullpath, filename, enable_translation=False)

print("response->",response)

# get the open AI completion after large docs summerisation and embeddings

# get the query from user to search the embeddings
completion_questions = input()

df = utils.initialize(engine='davinci')
embeedings_engine="davinci"
prompt=""
model = "text-davinci-003"
limit_response=True
tokens_response=100
temperature=0.0
#response = utils.search_semantic_redis(df, completion_questions, n=3, pprint=False, engine=embeedings_engine)
#response = utils.get_semantic_answer(df, question=completion_questions, explicit_prompt=prompt ,model=model, engine=embeedings_engine, limit_response=limit_response, tokens_response=tokens_response, temperature=temperature)
#print("search_semantic_redis --->:",response)
#print(response['text'][1])


response = utils.get_semantic_answer(df, completion_questions, explicit_prompt="", model=model, engine='babbage', limit_response=True, tokens_response=100, temperature=0.0)
#print("after completion--->1",)

print("get_semantic_answer --->:1",f"{response}\n\n\n")
print("get_semantic_answer --->:2",f"{response[0].encode().decode()}\n\n\n")
#print(f"{response['choices'][0]['text'].encode().decode()}\n\n\n")


#opairesponse = openai.Embedding.create(input=[completion_questions], engine= os.getenv('OPENAI_EMBEDDINGS_ENGINE_DOC', 'text-search-davinci-doc-001'))
#print("********************")
#print(opairesponse)
