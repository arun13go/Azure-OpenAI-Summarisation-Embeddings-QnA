{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to create the summarisation for the large documents (more than 20-3o pages) \n",
    "import sys\n",
    "# set the path for utilities files if running local machine\n",
    "sys.path.append('c:/Arun/Workspace/OpenAI/Azure-OpenAI-Summarisation-Embeddings-QnA/utilities/')\n",
    "\n",
    "import os\n",
    "# get the open AI completion for summasiation\n",
    "from utilities import summarisation\n",
    "from utilities import utils\n",
    "from utilities import redisembeddings\n",
    "\n",
    "# set Openai environment variables\n",
    "os.environ[\"OPENAI_ENGINES\"] = \"text-davinci-003\"\n",
    "os.environ[\"OPENAI_EMBEDDINGS_ENGINE_DOC\"] = \"text-embedding-ada-002\"\n",
    "os.environ[\"OPENAI_EMBEDDINGS_ENGINE_QUERY\"] = \"text-embedding-ada-002\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"YOUR OPENAI RESOURCE ENDPOINT\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"YOUR OPENAI RESOURCE ENDPOINT KEY\"\n",
    "os.environ[\"OPENAI_CHUNK_LIMIT\"] = \"18000\"\n",
    "os.environ[\"REDIS_ADDRESS\"] = \"YOUR REDIS STORE ENDPOINT\"\n",
    "os.environ[\"REDIS_PASSWORD\"] = \"YOUR REDIS STORE ENDPOINT PASSWORD\"\n",
    "os.environ[\"FORM_RECOGNIZER_ENDPOINT\"] = \"YOUR FORM RECOGNIZER ENDPOINT\"\n",
    "os.environ[\"FORM_RECOGNIZER_KEY\"] = \"YOUR FORM RECOGNIZER ENDPOINT KEY\"\n",
    "os.environ['BLOB_ACCOUNT_NAME'] = \"YOUR BLOB STORAGE NAME\"\n",
    "os.environ['BLOB_ACCOUNT_KEY'] = \"YOUR BLOB STORAGE KEY\"\n",
    "os.environ['BLOB_CONTAINER_NAME'] = \"documents\"\n",
    "os.putenv('PAGES_PER_EMBEDDINGS',\"1\")\n",
    "\n",
    "\n",
    "\n",
    "# full path of the document that needs embed and search\n",
    "fullpath=\"DOCUMENT FULL PATH\"\n",
    "filename=\"DOCUMENT NAME\"\n",
    "\n",
    "# initialise all the required parameters for OpenAI to run\n",
    "df = summarisation.initialize(engine='davinci')\n",
    "\n",
    "# submit the docment to summarise before embeddings search\n",
    "response = summarisation.convert_file_and_add_summarisation_and_embed(fullpath, filename, enable_translation=False)\n",
    "\n",
    "print(\"response->\",response)\n",
    "\n",
    "# get the open AI completion after large docs summerisation and embeddings\n",
    "\n",
    "# get the query from user to search the embeddings\n",
    "completion_questions = input()\n",
    "\n",
    "df = utils.initialize(engine='davinci')\n",
    "embeedings_engine=\"davinci\"\n",
    "prompt=\"\"\n",
    "model = \"text-davinci-003\"\n",
    "limit_response=True\n",
    "tokens_response=100\n",
    "temperature=0.0\n",
    "#response = utils.search_semantic_redis(df, completion_questions, n=3, pprint=False, engine=embeedings_engine)\n",
    "#response = utils.get_semantic_answer(df, question=completion_questions, explicit_prompt=prompt ,model=model, engine=embeedings_engine, limit_response=limit_response, tokens_response=tokens_response, temperature=temperature)\n",
    "#print(\"search_semantic_redis --->:\",response)\n",
    "#print(response['text'][1])\n",
    "\n",
    "\n",
    "response = utils.get_semantic_answer(df, completion_questions, explicit_prompt=\"\", model=model, engine='babbage', limit_response=True, tokens_response=100, temperature=0.0)\n",
    "#print(\"after completion--->1\",)\n",
    "\n",
    "print(\"get_semantic_answer --->:1\",f\"{response}\\n\\n\\n\")\n",
    "print(\"get_semantic_answer --->:2\",f\"{response[0].encode().decode()}\\n\\n\\n\")\n",
    "#print(f\"{response['choices'][0]['text'].encode().decode()}\\n\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
